{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current TODO:\n",
    "- add pad token ignorence\n",
    "- save and load model\n",
    "- find appropriate data size to fit gpu\n",
    "- add state encoding to model\n",
    "- change iterations over dataset to dataloader \n",
    "\n",
    "Global TODO:\n",
    "- setup ALFRED venv and run simulation\n",
    "- comment functions in model and dataset\n",
    "- make model with ResNet image processor\n",
    "- run model on ALFRED sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.MultyModalGPT2 import MultyModalGPT2\n",
    "from src.data.shemas import ConfigData, ConfigTraining\n",
    "from src.data.datasets import AlfredDataset\n",
    "from src.pipelines.train_pipeline import train_loop\n",
    "from src.utils import decode_from_logits\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cfg = ConfigTraining(\n",
    "    train_data_path = \"../data/raw/json_feat_2.1.0/json_feat_2.1.0/train/\",\n",
    "    test_data_path = \"../data/raw/json_feat_2.1.0/json_feat_2.1.0/valid_seen/\",\n",
    "    epoch_num=1,\n",
    "    data_samples_num=100\n",
    ")\n",
    "\n",
    "cfg = ConfigData(\n",
    "    device=\"cuda\",\n",
    "    train_cfg=train_cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AlfredDataset(cfg)\n",
    "test_dataset = AlfredDataset(cfg, dataset_type=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmgpt = MultyModalGPT2(cfg)\n",
    "mmgpt.train()\n",
    "# mmgpt.set_bias_training()\n",
    "opt = AdamW(mmgpt.get_trainable_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7d63e0f5bc400bbd917c06c95e5c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TRAIN:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m train_loop(mmgpt, train_dataset, test_dataset, opt, cfg)\n",
      "File \u001b[1;32mc:\\max\\proga\\masterdegree\\alfred\\src\\pipelines\\train_pipeline.py:106\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(model, train_dataset, test_dataset, opt, cfg)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(cfg\u001b[39m.\u001b[39mtrain_cfg\u001b[39m.\u001b[39mepoch_num):\n\u001b[0;32m    105\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m.\u001b[39mtrain_cfg\u001b[39m.\u001b[39mepoch_num\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 106\u001b[0m     train_history \u001b[39m=\u001b[39m train_batch(model, train_dataset, opt, cfg)\n\u001b[0;32m    107\u001b[0m     train_eval_history \u001b[39m=\u001b[39m eval_batch(model, train_dataset, cfg)\n\u001b[0;32m    108\u001b[0m     test_eval_history \u001b[39m=\u001b[39m eval_batch(model, test_dataset, cfg)\n",
      "File \u001b[1;32mc:\\max\\proga\\masterdegree\\alfred\\src\\pipelines\\train_pipeline.py:40\u001b[0m, in \u001b[0;36mtrain_batch\u001b[1;34m(model, dataset, opt, cfg)\u001b[0m\n\u001b[0;32m     38\u001b[0m opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     39\u001b[0m out \u001b[39m=\u001b[39m model(sample_part)\n\u001b[1;32m---> 40\u001b[0m out[\u001b[39m\"\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     41\u001b[0m opt\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     43\u001b[0m loss_history\u001b[39m.\u001b[39mappend(out[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Max\\Proga\\python_venv\\.venv\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Max\\Proga\\python_venv\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = train_loop(mmgpt, train_dataset, test_dataset, opt, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [0.7300925400853157],\n",
       " 'train_acc': [0.0],\n",
       " 'test_loss': [1.2421517351269722],\n",
       " 'test_acc': [0.0]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 768])\n",
      "torch.Size([8, 1, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\n\\xa0                         can,, The Force\\n up a first.. start it the alarm.\\n on, right the lamper.\\n up the lamp clock and the dresser. pick on and and at turn at the dress. turn the lamp on. turn\\xa0                          face actions: pick turn                           you the doing to:                           TheTheTheTheTheTheTheTheTheTheTheTheTheTheTheTheTheTheTheThe at\\nThe',\n",
       " '\\n\\xa0                         can the,\\n.\\n- the item.. press it the alarm.\\n on. right the lamper.\\n up the alarm clock. the dresser. turn right and face at look turn the dress. turn right clock on. and                          s task are. at the turn\\xa0                          you the doing to:                           TheTheTheTheTheTheTheTheTheTheTheTheTheTheTheTheTheThement\\n\\n',\n",
       " 'The\\xa0                         can my the,\\n:. a the first.. the it. clock.\\n on. the the light..\\n up the lamp and and the lamper.\\n left and turn at see turn the dress. turn right lamp. and turn \\xa0                         name actions are turn at,\\n to. turn                           is the doing to?                           TheTheTheTheTheTheTheTheTheTheTheTheTheTheThe to\\nThe',\n",
       " 'The\\xa0                         can,,.. \" up to \".. the the the alarm.\\n on. turn the light..\\n up the lamp.. the clocker.\\n on. the at right the the alarm.\\n on.. the and                           clock..\\n at.\\n the.\\n..\\n                           is the are. on\\n                          TheTheTheTheTheTheTheTheTheTheTheTheate\\n\\n',\n",
       " '\\n\\xa0                         can,,\\n: \" a to next.. the on the clock on\\n the, right the lamp..\\n the the. the. the righter. the the and the at the the,.. the the pick. the the\\n                        ,,.\\n at the\\n the.\\n the...\\n                           the the doing??\\n                          TheTheTheTheTheTheTheTheThe at\\nThe',\n",
       " '\\n                          can the,\\n Force \" up the \".. go. the alarm.\\n the. the the wall..\\n up the lamp turn. the other... the and the at the the the dress. turn the lamp. and\\n\\xa0 \\xa0                        name post are the and the\\n the. ahead....\\n \\xa0                       \\'s the?::                           TheTheTheTheTheTheThe a\\n\\n',\n",
       " '\\n\\xa0\\xa0                        can,,\\n:  up. phone clock. start on. alarm.\\n the. turn the doorer. The up the alarm clock. the dresser. turn right and face at turn turn the dress. turn right lamp on the turn                           name task are You at the You the. turnahead. move.. move. lookup.. pick\\xa0                          you the do:: You                          TheTheTheThe at.The',\n",
       " ',\\xa0                         can,\\n,. Force\\n up the same.. the the the alarm on\\n on and turn. lamp.. The up the alarm and and the clocker.\\n the the turn at turn turn the dress. The the lamp and the turn!!!\\xa0                         name page:\\n at the turn the. turnahead. move the. turn. rotate.. pickup. lookup\\xa0                          actions your do::                           Theate\\n:']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample = train_dataset[0]\n",
    "# sample[\"images_features\"] = sample[\"images_features\"].to(cfg.device)\n",
    "\n",
    "# data_size = min(8,  sample[\"images_features\"].shape[0])\n",
    "# sample_part = {\n",
    "#     k: v[:data_size] for k, v in sample.items()\n",
    "# }\n",
    "\n",
    "# out = mmgpt(sample_part)\n",
    "\n",
    "# predictions = decode_from_logits(mmgpt.mmtokenizer.tokenizer, out[\"logits\"])\n",
    "# predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
